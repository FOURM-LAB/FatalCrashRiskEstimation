{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb2fda5",
   "metadata": {},
   "source": [
    "This script demostrate the training (i.e., finetuning) of the Fatal Crash Risk Estiamtion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities as UT\n",
    "from mydataset import MyDataset_MultiScale_SameAug as MyDataset_MultiScale\n",
    "from myops import Train_FT_MTSL_MTHD_V2, Test_FT_MTSL_MTHD_V2\n",
    "import myaugmentation as MyAug\n",
    "import mymodels\n",
    "\n",
    "import os \n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.cuda.amp import GradScaler#, autocast\n",
    "import torch.nn.parallel as parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbe96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "    # Get the names of the available GPUs\n",
    "    gpu_names = [torch.cuda.get_device_name(i) for i in range(num_gpus)]\n",
    "    print(\"Available GPUs:\")\n",
    "    for i, gpu_name in enumerate(gpu_names):\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 40\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "num_classes = 2\n",
    "\n",
    "pretrained = True \n",
    "learning_rate = 1e-4\n",
    "class_weights = [1.370, 3.681] # inverse frequency for crossview\n",
    "optimizer_name = \"AdamW\"\n",
    "\n",
    "model_name = 'Res50-FineTune-MTSL-MTHD-V2'+'_'+optimizer_name+'_'+str(learning_rate)+'_'+str(batch_size)\n",
    "training_trail = 'CrossView-Train_PreTrain-MultiScale-24'\n",
    "\n",
    "ckpt_name = \"ResNet50_Pre-Train_MultiScale/ckpt/ResNet50_Pre-Train_MultiScale_24_0.017479911147395014.pth\"\n",
    "\n",
    "project_directory = \"../experimental_results\"\n",
    "metadataTrain = \"../metadata/train.csv\" # list of training samples\n",
    "metadataVal = \"../metadata/val_crossview.csv\" # list of validation samples\n",
    "metadataTest = \"../metadata/test_crossview.csv\" # list of test samples\n",
    "\n",
    "output_path = os.path.join(project_directory, model_name.split(\"_\")[0], str(training_trail))\n",
    "ckpt_path = os.path.join(project_directory, ckpt_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train_dataset = MyDataset_MultiScale(if_test=False, \n",
    "                                     basic_transform=MyAug.base_aug(), \n",
    "                                     metadata=metadataTrain)\n",
    "val_dataset = MyDataset_MultiScale(if_test=True, \n",
    "                                   basic_transform=MyAug.base_aug(), \n",
    "                                   metadata=metadataVal)\n",
    "test_dataset = MyDataset_MultiScale(if_test=True, \n",
    "                                    basic_transform=MyAug.base_aug(), \n",
    "                                    metadata=metadataTest)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                              num_workers=num_workers, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                            num_workers=num_workers, shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                             num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained weights\n",
    "state_dict = torch.load(ckpt_path)\n",
    "\n",
    "# create a mapping of old key names to new key names\n",
    "key_map = {}\n",
    "for key in state_dict.keys():\n",
    "    new_key = key.replace(\"module.\", \"\")  # remove \"model.\" prefix\n",
    "    key_map[key] = new_key\n",
    "\n",
    "# rename the keys in the state dictionary\n",
    "renamed_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    renamed_state_dict[key_map[key]] = value\n",
    "    \n",
    "# Load the model    \n",
    "model = mymodels.ResNet50_MultiScale_MultiHead_V2(pretrain_weights=renamed_state_dict)\n",
    "model = parallel.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "class_weights = torch.tensor(class_weights).to(device) \n",
    "criterion = nn.CrossEntropyLoss(class_weights)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler = GradScaler() # the scaler for mixed precision training\n",
    "\n",
    "writer = SummaryWriter(log_dir=os.path.join(output_path, \"log\", model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c20fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    \n",
    "    model, epoch_loss, train_acc = Train_FT_MTSL_MTHD_V2(epoch, train_dataloader, model, criterion, optimizer, \n",
    "                                            scheduler, scaler, device, writer)        \n",
    "    \n",
    "    _, val_acc = Test_FT_MTSL_MTHD_V2(epoch, val_dataloader, model, criterion, device, writer, mode=\"Val\")\n",
    "\n",
    "    _, test_acc = Test_FT_MTSL_MTHD_V2(epoch, test_dataloader, model, criterion, device, writer, mode=\"Test\")\n",
    "\n",
    "    torch.save(model.state_dict(), \n",
    "               os.path.join(output_path, model_name+f'_{epoch}_{train_acc}_{val_acc}_{test_acc}.pth'))\n",
    "    \n",
    "    print(\"Epoch: %d\\t Train [loss/acc]: [%.4f/%.4f]\\t Val/Test Acc: %.4f/%.4f\" \n",
    "          %(epoch, epoch_loss, train_acc, val_acc, test_acc))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
